{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_o5z0BZvzHq6",
    "outputId": "5ae7d12a-11ef-408f-ec5e-a2127c11ee8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LN1N0stJwxdV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D, Dense, Flatten, Dropout, MaxPooling2D\n",
    "from keras.models import Sequential, save_model\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model,load_model\n",
    "from keras.layers import Input, Dense, Add,Activation, AveragePooling2D, BatchNormalization, Flatten, Conv2D, MaxPooling2D, Dropout, ZeroPadding2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras import regularizers\n",
    "import scipy.misc\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7mpfokyiyn5-"
   },
   "outputs": [],
   "source": [
    "root_directory=\"/content/drive/MyDrive/DATASETS/\"\n",
    "survival_words_directory=\"/content/drive/MyDrive/DATASETS/25_survival_words/\"\n",
    "alphabets_directory=\"/content/drive/MyDrive/DATASETS/ALPHABETS/\"\n",
    "numbers_directory=\"/content/drive/MyDrive/DATASETS/NUMBERS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "iHFE9KsI05pw"
   },
   "outputs": [],
   "source": [
    "k=0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating numpy arrays of elements an labelling array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tlG0ZBcvz0o9"
   },
   "outputs": [],
   "source": [
    "def load_dataset(directory,k):\n",
    "  images=[]\n",
    "  labels=[]\n",
    "  for idx,label in enumerate(uniq_labels):\n",
    "    for file in os.listdir(directory + label):\n",
    "      filepath = directory + label +\"/\" + file\n",
    "      img = cv2.resize(cv2.imread(filepath),(50,50))\n",
    "      images.append(img)\n",
    "      labels.append(k)\n",
    "    k+=1\n",
    "  images = np.asarray(images)\n",
    "  labels = np.asarray(labels)\n",
    "  return images, labels,k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_Ga2kbhplYR5"
   },
   "outputs": [],
   "source": [
    "# uniq_labels=sorted(os.listdir(alphabets_directory))\n",
    "# print(uniq_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pjg6OXTO1nWt"
   },
   "outputs": [],
   "source": [
    "uniq_labels=sorted(os.listdir(numbers_directory))\n",
    "X_numbers_directory,y_numbers_directory,k=load_dataset(numbers_directory,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RSdYfPquDOOF"
   },
   "outputs": [],
   "source": [
    "# /content/drive/MyDrive/DATASETS/NUMBERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TCj2kwvR-ELb",
    "outputId": "37951dfb-8009-4d2e-9da8-d497f71ef362"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 9, 9, 9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_numbers_directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "WFNry9Q74fuk"
   },
   "outputs": [],
   "source": [
    "uniq_labels=sorted(os.listdir(alphabets_directory))\n",
    "X_alphabets_directory,y_alphabets_directory,k=load_dataset(alphabets_directory,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hCtZQmSqltyY",
    "outputId": "9e3d5b9b-aea2-4058-e8af-77ab218c105b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10, 10, ..., 34, 34, 34])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_alphabets_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-PkTSvxZ6P3U"
   },
   "outputs": [],
   "source": [
    "uniq_labels=sorted(os.listdir(survival_words_directory))\n",
    "X_survival_words_directory,y_survival_words_directory,k=load_dataset(survival_words_directory,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eK6HcZSL7qsh",
    "outputId": "c007ac85-1d7f-478c-ebf3-0b3019399d68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 35, 35, ..., 59, 59, 59])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_survival_words_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AAlKyRer7sIJ"
   },
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "lcyyqHLMjswn"
   },
   "outputs": [],
   "source": [
    "X=np.concatenate((X_numbers_directory,X_alphabets_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Okvdf-GbkMmz"
   },
   "outputs": [],
   "source": [
    "X=np.concatenate((X,X_survival_words_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "GKmTIu-PkVbt"
   },
   "outputs": [],
   "source": [
    "y=np.concatenate((y_numbers_directory,y_alphabets_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "RHtlZHHrkdyW"
   },
   "outputs": [],
   "source": [
    "y=np.concatenate((y,y_survival_words_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JsdGZs00dyQX",
    "outputId": "b938222b-563a-44c5-dcf0-b5d718699873"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 59, 59, 59])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "rdDMt6jbsoZ0"
   },
   "outputs": [],
   "source": [
    "# list(y.keys())\n",
    "y = to_categorical(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Otmh-cbEkhVO"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "aNg5xH7mkorj"
   },
   "outputs": [],
   "source": [
    "X_train = X_train / 255.\n",
    "X_test = X_test/ 255."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fOH060y6kqdY",
    "outputId": "0d11422f-c913-42f8-d598-5d72afb325f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 64)        1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 22, 22, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 11, 11, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 9, 9, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               131200    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 60)                7740      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 214,588\n",
      "Trainable params: 214,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation = 'relu', input_shape=(50,50,3) ))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Dense(y.shape[1], activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dKrxfjeAlAo9",
    "outputId": "159a3b0a-b56e-4728-bc2e-ad852c8ff88e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11600, 60)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-86Usg-WlD_l",
    "outputId": "34e36ca2-e9c0-4dfc-b1fe-e0e7f357c846"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "DXvQO8EOeGHH"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', metrics=['accuracy'], loss='categorical_crossentropy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kwuqv0HbfAPf",
    "outputId": "ad2d8bda-26fa-4071-e16c-fd843cab6443"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "68/68 [==============================] - 10s 18ms/step - loss: 3.3772 - accuracy: 0.1950\n",
      "Epoch 2/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.9123 - accuracy: 0.7781\n",
      "Epoch 3/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.3009 - accuracy: 0.9231\n",
      "Epoch 4/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.1549 - accuracy: 0.9586\n",
      "Epoch 5/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0816 - accuracy: 0.9789\n",
      "Epoch 6/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0605 - accuracy: 0.9834\n",
      "Epoch 7/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0423 - accuracy: 0.9877\n",
      "Epoch 8/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0347 - accuracy: 0.9893\n",
      "Epoch 9/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0290 - accuracy: 0.9901\n",
      "Epoch 10/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0236 - accuracy: 0.9928\n",
      "Epoch 11/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0192 - accuracy: 0.9937\n",
      "Epoch 12/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0239 - accuracy: 0.9932\n",
      "Epoch 13/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0143 - accuracy: 0.9963\n",
      "Epoch 14/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0123 - accuracy: 0.9969\n",
      "Epoch 15/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0094 - accuracy: 0.9972\n",
      "Epoch 16/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0097 - accuracy: 0.9974\n",
      "Epoch 17/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0090 - accuracy: 0.9972\n",
      "Epoch 18/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0177 - accuracy: 0.9943\n",
      "Epoch 19/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0096 - accuracy: 0.9976\n",
      "Epoch 20/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0284 - accuracy: 0.9902\n",
      "Epoch 21/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0105 - accuracy: 0.9966\n",
      "Epoch 22/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0083 - accuracy: 0.9971\n",
      "Epoch 23/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0154 - accuracy: 0.9946\n",
      "Epoch 24/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0088 - accuracy: 0.9977\n",
      "Epoch 25/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0082 - accuracy: 0.9981\n",
      "Epoch 26/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0055 - accuracy: 0.9987\n",
      "Epoch 27/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0037 - accuracy: 0.9991\n",
      "Epoch 28/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "Epoch 29/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0070 - accuracy: 0.9980\n",
      "Epoch 30/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0119 - accuracy: 0.9964\n",
      "Epoch 31/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0069 - accuracy: 0.9972\n",
      "Epoch 32/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0064 - accuracy: 0.9982\n",
      "Epoch 33/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0067 - accuracy: 0.9986\n",
      "Epoch 34/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 35/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0105 - accuracy: 0.9970\n",
      "Epoch 36/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0075 - accuracy: 0.9976\n",
      "Epoch 37/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0091 - accuracy: 0.9972\n",
      "Epoch 38/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0050 - accuracy: 0.9989\n",
      "Epoch 39/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0047 - accuracy: 0.9985\n",
      "Epoch 40/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0073 - accuracy: 0.9978\n",
      "Epoch 41/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0100 - accuracy: 0.9972\n",
      "Epoch 42/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "Epoch 43/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0023 - accuracy: 0.9996\n",
      "Epoch 44/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 45/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0028 - accuracy: 0.9992\n",
      "Epoch 46/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0046 - accuracy: 0.9988\n",
      "Epoch 47/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 48/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0121 - accuracy: 0.9957\n",
      "Epoch 49/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0103 - accuracy: 0.9970\n",
      "Epoch 50/100\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 51/100\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 52/100\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 0.0035 - accuracy: 0.9987\n",
      "Epoch 53/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0049 - accuracy: 0.9985\n",
      "Epoch 54/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0072 - accuracy: 0.9977\n",
      "Epoch 55/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0072 - accuracy: 0.9976\n",
      "Epoch 56/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0062 - accuracy: 0.9982\n",
      "Epoch 57/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0037 - accuracy: 0.9989\n",
      "Epoch 58/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0073 - accuracy: 0.9971\n",
      "Epoch 59/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0024 - accuracy: 0.9991\n",
      "Epoch 60/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0042 - accuracy: 0.9985\n",
      "Epoch 61/100\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 0.0047 - accuracy: 0.9984\n",
      "Epoch 62/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0061 - accuracy: 0.9975\n",
      "Epoch 63/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0057 - accuracy: 0.9983\n",
      "Epoch 64/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0035 - accuracy: 0.9988\n",
      "Epoch 65/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0024 - accuracy: 0.9987\n",
      "Epoch 66/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 67/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 5.3292e-04 - accuracy: 0.9998\n",
      "Epoch 68/100\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 0.0027 - accuracy: 0.9995\n",
      "Epoch 69/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0015 - accuracy: 0.9992\n",
      "Epoch 70/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0024 - accuracy: 0.9991\n",
      "Epoch 71/100\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 0.0038 - accuracy: 0.9988\n",
      "Epoch 72/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0020 - accuracy: 0.9996\n",
      "Epoch 73/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 7.2359e-04 - accuracy: 0.9998\n",
      "Epoch 74/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0011 - accuracy: 0.9995\n",
      "Epoch 75/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0067 - accuracy: 0.9975\n",
      "Epoch 76/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0024 - accuracy: 0.9991\n",
      "Epoch 77/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0088 - accuracy: 0.9972\n",
      "Epoch 78/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0114 - accuracy: 0.9976\n",
      "Epoch 79/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0075 - accuracy: 0.9985\n",
      "Epoch 80/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0109 - accuracy: 0.9966\n",
      "Epoch 81/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 82/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0042 - accuracy: 0.9989\n",
      "Epoch 83/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 84/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 85/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0022 - accuracy: 0.9991\n",
      "Epoch 86/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0028 - accuracy: 0.9991\n",
      "Epoch 87/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 88/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 89/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 90/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 5.9581e-04 - accuracy: 0.9998\n",
      "Epoch 91/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 92/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 93/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0028 - accuracy: 0.9991\n",
      "Epoch 94/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 95/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0014 - accuracy: 0.9996\n",
      "Epoch 96/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0010 - accuracy: 0.9995\n",
      "Epoch 97/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0067 - accuracy: 0.9982\n",
      "Epoch 98/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0026 - accuracy: 0.9996\n",
      "Epoch 99/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 100/100\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 0.0017 - accuracy: 0.9995\n"
     ]
    }
   ],
   "source": [
    "fit = model.fit(X_train, Y_train, batch_size=138, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lpJTvL0VfISG",
    "outputId": "e38ac584-8404-42c2-ff82-24c471deadf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_xFqFIEfvU5",
    "outputId": "c6ae6011-1ac6-4f9e-800b-4f435c614919"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.95689655172414"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, y_pred.round())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "z9n5v_Qxfvqd"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wuK0kBkIf1Wb",
    "outputId": "c3f67ac9-5577-44d4-cb2b-caeeb8d5ede4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        75\n",
      "           1       1.00      1.00      1.00        58\n",
      "           2       1.00      1.00      1.00        23\n",
      "           3       1.00      1.00      1.00        61\n",
      "           4       1.00      1.00      1.00        64\n",
      "           5       1.00      1.00      1.00        59\n",
      "           6       1.00      1.00      1.00        21\n",
      "           7       0.96      1.00      0.98        24\n",
      "           8       1.00      1.00      1.00        13\n",
      "           9       1.00      1.00      1.00        20\n",
      "          10       1.00      1.00      1.00        77\n",
      "          11       1.00      1.00      1.00        75\n",
      "          12       1.00      1.00      1.00        60\n",
      "          13       1.00      1.00      1.00        19\n",
      "          14       1.00      1.00      1.00        16\n",
      "          15       1.00      1.00      1.00        23\n",
      "          16       1.00      1.00      1.00        20\n",
      "          17       1.00      1.00      1.00        64\n",
      "          18       1.00      1.00      1.00        30\n",
      "          19       1.00      1.00      1.00        51\n",
      "          20       1.00      1.00      1.00        67\n",
      "          21       1.00      1.00      1.00        56\n",
      "          22       1.00      1.00      1.00        25\n",
      "          23       1.00      1.00      1.00        53\n",
      "          24       1.00      1.00      1.00        22\n",
      "          25       1.00      1.00      1.00        19\n",
      "          26       1.00      1.00      1.00        14\n",
      "          27       1.00      1.00      1.00        19\n",
      "          28       1.00      1.00      1.00        63\n",
      "          29       1.00      1.00      1.00        31\n",
      "          30       1.00      1.00      1.00        22\n",
      "          31       1.00      1.00      1.00        67\n",
      "          32       1.00      1.00      1.00        19\n",
      "          33       1.00      1.00      1.00        61\n",
      "          34       1.00      0.98      0.99        59\n",
      "          35       1.00      1.00      1.00        70\n",
      "          36       1.00      1.00      1.00        50\n",
      "          37       1.00      1.00      1.00        66\n",
      "          38       1.00      1.00      1.00        33\n",
      "          39       1.00      1.00      1.00        65\n",
      "          40       1.00      1.00      1.00        73\n",
      "          41       0.00      0.00      0.00         0\n",
      "          42       1.00      1.00      1.00        35\n",
      "          43       1.00      1.00      1.00        24\n",
      "          44       1.00      1.00      1.00        57\n",
      "          45       0.00      0.00      0.00         0\n",
      "          46       1.00      1.00      1.00        15\n",
      "          47       0.00      0.00      0.00         0\n",
      "          48       1.00      1.00      1.00        54\n",
      "          49       0.00      0.00      0.00         0\n",
      "          50       0.00      0.00      0.00         0\n",
      "          51       1.00      1.00      1.00        62\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       1.00      1.00      1.00        79\n",
      "          54       1.00      1.00      1.00         8\n",
      "          55       1.00      1.00      1.00        61\n",
      "          56       1.00      1.00      1.00        28\n",
      "          57       1.00      1.00      1.00        61\n",
      "          58       1.00      1.00      1.00        26\n",
      "          59       1.00      1.00      1.00         3\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2320\n",
      "   macro avg       0.90      0.90      0.90      2320\n",
      "weighted avg       1.00      1.00      1.00      2320\n",
      " samples avg       1.00      1.00      1.00      2320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred.round(), Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SGbIUhOHf3id",
    "outputId": "31854049-c295-4ac7-adbb-12bca0373a3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 15ms/step - loss: 0.0019 - accuracy: 0.9996\n",
      "Accuracy:  99.95689392089844\n"
     ]
    }
   ],
   "source": [
    "accuracy = model.evaluate(X_test,Y_test,batch_size=138)\n",
    "print(\"Accuracy: \",accuracy[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "hBX1FbdTf6PS"
   },
   "outputs": [],
   "source": [
    "# model.save_weights('/content/drive/MyDrive/Freelance/NomanRafique/')\n",
    "model.save('my_model.h5') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "w2a8SirfD2RV"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/MyDrive/my_model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbIh3xz_uCaE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
